{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploratory and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data\n",
    "data = pd.read_csv('./Data/credit_default_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18895</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25559.0</td>\n",
       "      <td>26134.0</td>\n",
       "      <td>26715.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25102</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140387.0</td>\n",
       "      <td>128112.0</td>\n",
       "      <td>115514.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28867</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26038.0</td>\n",
       "      <td>28607.0</td>\n",
       "      <td>27997.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1842</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72391.0</td>\n",
       "      <td>61298.0</td>\n",
       "      <td>62193.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3371</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0    18895    70000.0  1.0        3.0       2.0  34.0    0.0    0.0    0.0   \n",
       "1    25102   390000.0  2.0        2.0       2.0  26.0    2.0    2.0    2.0   \n",
       "2    28867    60000.0  1.0        1.0       2.0  27.0    0.0    0.0    0.0   \n",
       "3     1842   140000.0  2.0        2.0       1.0  55.0    0.0    0.0    0.0   \n",
       "4     3371    50000.0  1.0        1.0       2.0  29.0    2.0    2.0    2.0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0    0.0  ...    25559.0    26134.0    26715.0    1700.0    1500.0    2000.0   \n",
       "1    0.0  ...   140387.0   128112.0   115514.0    5000.0    3000.0    5000.0   \n",
       "2    0.0  ...    26038.0    28607.0    27997.0    1378.0    1406.0    3000.0   \n",
       "3    0.0  ...    72391.0    61298.0    62193.0    4200.0    2822.0    2336.0   \n",
       "4    0.0  ...     1047.0        0.0        0.0    3000.0       0.0    1000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0    1000.0    1000.0    2000.0                           0  \n",
       "1    4548.0    4100.0    3300.0                           0  \n",
       "2    3000.0       0.0     923.0                           1  \n",
       "3    2588.0    2250.0    2491.0                           0  \n",
       "4       0.0       0.0       0.0                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.00000</td>\n",
       "      <td>19798.000000</td>\n",
       "      <td>19839.000000</td>\n",
       "      <td>19801.000000</td>\n",
       "      <td>19830.000000</td>\n",
       "      <td>19786.000000</td>\n",
       "      <td>19805.000000</td>\n",
       "      <td>19781.000000</td>\n",
       "      <td>19783.000000</td>\n",
       "      <td>19801.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19835.000000</td>\n",
       "      <td>19819.000000</td>\n",
       "      <td>19803.000000</td>\n",
       "      <td>19796.000000</td>\n",
       "      <td>1.981600e+04</td>\n",
       "      <td>19788.000000</td>\n",
       "      <td>19803.000000</td>\n",
       "      <td>19821.000000</td>\n",
       "      <td>19804.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15008.05080</td>\n",
       "      <td>166701.872916</td>\n",
       "      <td>1.604063</td>\n",
       "      <td>1.851927</td>\n",
       "      <td>1.555371</td>\n",
       "      <td>35.476347</td>\n",
       "      <td>-0.020096</td>\n",
       "      <td>-0.130681</td>\n",
       "      <td>-0.166153</td>\n",
       "      <td>-0.222666</td>\n",
       "      <td>...</td>\n",
       "      <td>43048.544643</td>\n",
       "      <td>40210.403401</td>\n",
       "      <td>38798.676110</td>\n",
       "      <td>5495.856234</td>\n",
       "      <td>5.809670e+03</td>\n",
       "      <td>5208.033808</td>\n",
       "      <td>4796.357168</td>\n",
       "      <td>4828.116694</td>\n",
       "      <td>5235.934357</td>\n",
       "      <td>0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8679.93316</td>\n",
       "      <td>129493.677795</td>\n",
       "      <td>0.489063</td>\n",
       "      <td>0.789254</td>\n",
       "      <td>0.521595</td>\n",
       "      <td>9.233460</td>\n",
       "      <td>1.115072</td>\n",
       "      <td>1.196540</td>\n",
       "      <td>1.200058</td>\n",
       "      <td>1.171144</td>\n",
       "      <td>...</td>\n",
       "      <td>64256.075173</td>\n",
       "      <td>60862.131155</td>\n",
       "      <td>59664.796582</td>\n",
       "      <td>15174.610301</td>\n",
       "      <td>2.221102e+04</td>\n",
       "      <td>17443.277264</td>\n",
       "      <td>15394.675977</td>\n",
       "      <td>15295.323825</td>\n",
       "      <td>18104.454473</td>\n",
       "      <td>0.414729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7471.25000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2256.000000</td>\n",
       "      <td>1716.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>8.487500e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15003.00000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18970.000000</td>\n",
       "      <td>18070.000000</td>\n",
       "      <td>16985.000000</td>\n",
       "      <td>2087.000000</td>\n",
       "      <td>2.004000e+03</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22532.50000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54400.500000</td>\n",
       "      <td>50120.500000</td>\n",
       "      <td>48888.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4448.000000</td>\n",
       "      <td>4000.500000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.00000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>505000.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.000000</td>\n",
       "      <td>528897.000000</td>\n",
       "      <td>388071.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cust_id       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  20000.00000    19798.000000  19839.000000  19801.000000  19830.000000   \n",
       "mean   15008.05080   166701.872916      1.604063      1.851927      1.555371   \n",
       "std     8679.93316   129493.677795      0.489063      0.789254      0.521595   \n",
       "min        2.00000    10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7471.25000    50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15003.00000   140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22532.50000   240000.000000      2.000000      2.000000      2.000000   \n",
       "max    30000.00000  1000000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  19786.000000  19805.000000  19781.000000  19783.000000  19801.000000   \n",
       "mean      35.476347     -0.020096     -0.130681     -0.166153     -0.222666   \n",
       "std        9.233460      1.115072      1.196540      1.200058      1.171144   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       75.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   19835.000000   19819.000000   19803.000000   19796.000000   \n",
       "mean   ...   43048.544643   40210.403401   38798.676110    5495.856234   \n",
       "std    ...   64256.075173   60862.131155   59664.796582   15174.610301   \n",
       "min    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n",
       "25%    ...    2256.000000    1716.000000    1256.000000     990.000000   \n",
       "50%    ...   18970.000000   18070.000000   16985.000000    2087.000000   \n",
       "75%    ...   54400.500000   50120.500000   48888.000000    5002.000000   \n",
       "max    ...  891586.000000  927171.000000  961664.000000  505000.000000   \n",
       "\n",
       "           PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  1.981600e+04   19788.000000   19803.000000   19821.000000   \n",
       "mean   5.809670e+03    5208.033808    4796.357168    4828.116694   \n",
       "std    2.221102e+04   17443.277264   15394.675977   15295.323825   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    8.487500e+02     390.000000     291.000000     269.000000   \n",
       "50%    2.004000e+03    1800.000000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4448.000000    4000.500000    4010.000000   \n",
       "max    1.684259e+06  896040.000000  528897.000000  388071.000000   \n",
       "\n",
       "            PAY_AMT6  default.payment.next.month  \n",
       "count   19804.000000                20000.000000  \n",
       "mean     5235.934357                    0.220700  \n",
       "std     18104.454473                    0.414729  \n",
       "min         0.000000                    0.000000  \n",
       "25%       100.000000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4000.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXSElEQVR4nO3df5Dc9X3f8eerUkxku9gYwpWRlEqOZSf8sKfmQtWkyZyjtshOxqIzMCMXB9llRhNKXbclE0MyU/7oaAbaUCeQQkZjKMJlwCpxI7UubhjolnbCjwjHthCE+GIonFGsEDuEc8aYw+/+sR+169NJd9rdu9Vxz8fMzn33/f1+9vt5nzT72u/3u7uXqkKSpL826glIkk4NBoIkCTAQJEmNgSBJAgwESVKzetQT6NdZZ51VGzZs6Gvsd77zHd7ylrcMd0KnOHteGex5ZRik5yeeeOKlqvqRudYt20DYsGEDBw4c6Gtsp9NhYmJiuBM6xdnzymDPK8MgPSf5P8dbN+8poyR3JDmS5MlZ9U8keSbJoST/pqd+XZLJtu7invqFSQ62dTcnSaufluRzrf5Ykg19dSlJGshCriHcCWztLST5ALANeG9VnQf8equfC2wHzmtjbk2yqg27DdgJbGq3o495JfDtqnoX8GngxgH6kST1ad5AqKqHgW/NKl8F3FBVr7ZtjrT6NuDeqnq1qp4FJoGLkpwDnF5Vj1T3o9F3AZf0jNnTlu8Dthw9epAkLZ1+ryG8G/iZJLuA7wK/XFV/AKwFHu3ZbqrVXmvLs+u0ny8AVNVMkpeBM4GXZu80yU66RxmMjY3R6XT6mvz09HTfY5cre14Z7HllWKye+w2E1cAZwGbgJ4G9Sd4JzPXKvk5QZ551P1is2g3sBhgfH69+L6p4EWplsOeVwZ6Hp9/PIUwBn6+ux4HvA2e1+vqe7dYBL7b6ujnq9I5Jshp4G8eeopIkLbJ+A+F3gZ8DSPJu4E10T/HsB7a3dw5tpHvx+PGqOgy8kmRzuz5wBbCvPdZ+YEdbvhR4qPwKVklacvOeMkpyDzABnJVkCrgeuAO4o70V9XvAjvYkfijJXuApYAa4uqpebw91Fd13LK0B7m83gNuBzyaZpHtksH04rUmSTsa8gVBVHznOqo8eZ/tdwK456geA8+eofxe4bL55SJIW17L9pPIgDn7jZT527RdGsu/nbvj5kexXkubjl9tJkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJKABQRCkjuSHGl/P3n2ul9OUknO6qldl2QyyTNJLu6pX5jkYFt3c5K0+mlJPtfqjyXZMKTeJEknYSFHCHcCW2cXk6wH/j7wfE/tXGA7cF4bc2uSVW31bcBOYFO7HX3MK4FvV9W7gE8DN/bTiCRpMPMGQlU9DHxrjlWfBn4FqJ7aNuDeqnq1qp4FJoGLkpwDnF5Vj1RVAXcBl/SM2dOW7wO2HD16kCQtndX9DEryYeAbVfWVWc/da4FHe+5PtdprbXl2/eiYFwCqaibJy8CZwEtz7Hcn3aMMxsbG6HQ6/UyfsTVwzQUzfY0dVL9zHtT09PTI9j0q9rwy2PPwnHQgJHkz8GvAP5hr9Ry1OkH9RGOOLVbtBnYDjI+P18TExHzTndMtd+/jpoN9ZeHAnrt8YiT77XQ69Pv7Wq7seWWw5+Hp511GPwZsBL6S5DlgHfClJH+D7iv/9T3brgNebPV1c9TpHZNkNfA25j5FJUlaRCcdCFV1sKrOrqoNVbWB7hP6+6vqT4H9wPb2zqGNdC8eP15Vh4FXkmxu1weuAPa1h9wP7GjLlwIPtesMkqQltJC3nd4DPAK8J8lUkiuPt21VHQL2Ak8BXwSurqrX2+qrgM/QvdD8J8D9rX47cGaSSeBfAtf22YskaQDznkivqo/Ms37DrPu7gF1zbHcAOH+O+neBy+abhyRpcflJZUkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJErCwP6F5R5IjSZ7sqf3bJH+U5KtJ/nOSt/esuy7JZJJnklzcU78wycG27ub2t5Vpf3/5c63+WJINw21RkrQQCzlCuBPYOqv2AHB+Vb0X+GPgOoAk5wLbgfPamFuTrGpjbgN2Apva7ehjXgl8u6reBXwauLHfZiRJ/Zs3EKrqYeBbs2q/V1Uz7e6jwLq2vA24t6perapngUngoiTnAKdX1SNVVcBdwCU9Y/a05fuALUePHiRJS2f1EB7jHwOfa8tr6QbEUVOt9lpbnl0/OuYFgKqaSfIycCbw0uwdJdlJ9yiDsbExOp1OXxMeWwPXXDAz/4aLoN85D2p6enpk+x4Ve14Z7Hl4BgqEJL8GzAB3Hy3NsVmdoH6iMccWq3YDuwHGx8drYmLiZKb7/9xy9z5uOjiMLDx5z10+MZL9djod+v19LVf2vDLY8/D0/S6jJDuAXwAub6eBoPvKf33PZuuAF1t93Rz1HxiTZDXwNmadopIkLb6+AiHJVuBTwIer6q96Vu0Htrd3Dm2ke/H48ao6DLySZHO7PnAFsK9nzI62fCnwUE/ASJKWyLznTZLcA0wAZyWZAq6n+66i04AH2vXfR6vql6rqUJK9wFN0TyVdXVWvt4e6iu47ltYA97cbwO3AZ5NM0j0y2D6c1iRJJ2PeQKiqj8xRvv0E2+8Cds1RPwCcP0f9u8Bl881DkrS4/KSyJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSc28gZDkjiRHkjzZU3tHkgeSfK39PKNn3XVJJpM8k+TinvqFSQ62dTen/THmJKcl+VyrP5Zkw5B7lCQtwEKOEO4Ets6qXQs8WFWbgAfbfZKcC2wHzmtjbk2yqo25DdgJbGq3o495JfDtqnoX8Gngxn6bkST1b95AqKqHgW/NKm8D9rTlPcAlPfV7q+rVqnoWmAQuSnIOcHpVPVJVBdw1a8zRx7oP2HL06EGStHRW9zlurKoOA1TV4SRnt/pa4NGe7aZa7bW2PLt+dMwL7bFmkrwMnAm8NHunSXbSPcpgbGyMTqfT3+TXwDUXzPQ1dlD9znlQ09PTI9v3qNjzymDPw9NvIBzPXK/s6wT1E405tli1G9gNMD4+XhMTE31MEW65ex83HRx26wvz3OUTI9lvp9Oh39/XcmXPK4M9D0+/7zL6ZjsNRPt5pNWngPU9260DXmz1dXPUf2BMktXA2zj2FJUkaZH1Gwj7gR1teQewr6e+vb1zaCPdi8ePt9NLryTZ3K4PXDFrzNHHuhR4qF1nkCQtoXnPmyS5B5gAzkoyBVwP3ADsTXIl8DxwGUBVHUqyF3gKmAGurqrX20NdRfcdS2uA+9sN4Hbgs0km6R4ZbB9KZ5KkkzJvIFTVR46zastxtt8F7JqjfgA4f476d2mBIkkaHT+pLEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgYMhCT/IsmhJE8muSfJDyd5R5IHknyt/TyjZ/vrkkwmeSbJxT31C5McbOtubn93WZK0hPoOhCRrgX8GjFfV+cAqun8P+VrgwaraBDzY7pPk3Lb+PGArcGuSVe3hbgN2ApvabWu/85Ik9WfQU0argTVJVgNvBl4EtgF72vo9wCVteRtwb1W9WlXPApPARUnOAU6vqkeqqoC7esZIkpZI34FQVd8Afh14HjgMvFxVvweMVdXhts1h4Ow2ZC3wQs9DTLXa2rY8uy5JWkKr+x3Yrg1sAzYCfwH8pyQfPdGQOWp1gvpc+9xJ99QSY2NjdDqdk5jx/ze2Bq65YKavsYPqd86Dmp6eHtm+R8WeVwZ7Hp6+AwH4e8CzVfVnAEk+D/wU8M0k51TV4XY66EjbfgpY3zN+Hd1TTFNteXb9GFW1G9gNMD4+XhMTE31N/Ja793HTwUFa799zl0+MZL+dTod+f1/LlT2vDPY8PINcQ3ge2Jzkze1dQVuAp4H9wI62zQ5gX1veD2xPclqSjXQvHj/eTiu9kmRze5wresZIkpZI3y+Tq+qxJPcBXwJmgD+k++r9rcDeJFfSDY3L2vaHkuwFnmrbX11Vr7eHuwq4E1gD3N9ukqQlNNB5k6q6Hrh+VvlVukcLc22/C9g1R/0AcP4gc5EkDcZPKkuSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUDBQISd6e5L4kf5Tk6SR/J8k7kjyQ5Gvt5xk921+XZDLJM0ku7qlfmORgW3dzkgwyL0nSyRv0COE3gS9W1Y8D7wOeBq4FHqyqTcCD7T5JzgW2A+cBW4Fbk6xqj3MbsBPY1G5bB5yXJOkk9R0ISU4Hfha4HaCqvldVfwFsA/a0zfYAl7TlbcC9VfVqVT0LTAIXJTkHOL2qHqmqAu7qGSNJWiKrBxj7TuDPgP+Q5H3AE8AngbGqOgxQVYeTnN22Xws82jN+qtVea8uz68dIspPukQRjY2N0Op2+Jj62Bq65YKavsYPqd86Dmp6eHtm+R8WeVwZ7Hp5BAmE18H7gE1X1WJLfpJ0eOo65rgvUCerHFqt2A7sBxsfHa2Ji4qQmfNQtd+/jpoODtN6/5y6fGMl+O50O/f6+lit7XhnseXgGuYYwBUxV1WPt/n10A+Kb7TQQ7eeRnu3X94xfB7zY6uvmqEuSllDfgVBVfwq8kOQ9rbQFeArYD+xotR3Avra8H9ie5LQkG+lePH68nV56Jcnm9u6iK3rGSJKWyKDnTT4B3J3kTcDXgY/TDZm9Sa4EngcuA6iqQ0n20g2NGeDqqnq9Pc5VwJ3AGuD+dpMkLaGBAqGqvgyMz7Fqy3G23wXsmqN+ADh/kLlIkgbjJ5UlSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBg/+BHElakTZc+4WR7fvOrW9ZlMf1CEGSBAwhEJKsSvKHSf5ru/+OJA8k+Vr7eUbPttclmUzyTJKLe+oXJjnY1t3c/rayJGkJDeMI4ZPA0z33rwUerKpNwIPtPknOBbYD5wFbgVuTrGpjbgN2ApvabesQ5iVJOgkDBUKSdcDPA5/pKW8D9rTlPcAlPfV7q+rVqnoWmAQuSnIOcHpVPVJVBdzVM0aStEQGPUL4DeBXgO/31Maq6jBA+3l2q68FXujZbqrV1rbl2XVJ0hLq+11GSX4BOFJVTySZWMiQOWp1gvpc+9xJ99QSY2NjdDqdBc11trE1cM0FM32NHVS/cx7U9PT0yPY9Kva8Moyq51E9h8Di9TzI205/Gvhwkg8BPwycnuQ/At9Mck5VHW6ng4607aeA9T3j1wEvtvq6OerHqKrdwG6A8fHxmpiY6Gvit9y9j5sOjuYdt89dPjGS/XY6Hfr9fS1X9rwyjKrnj434baeL0XPfp4yq6rqqWldVG+heLH6oqj4K7Ad2tM12APva8n5ge5LTkmyke/H48XZa6ZUkm9u7i67oGSNJWiKL8TL5BmBvkiuB54HLAKrqUJK9wFPADHB1Vb3exlwF3AmsAe5vN0nSEhpKIFRVB+i05T8Hthxnu13ArjnqB4DzhzEXSVJ//KSyJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSU3fgZBkfZL/keTpJIeSfLLV35HkgSRfaz/P6BlzXZLJJM8kubinfmGSg23dzUkyWFuSpJM1yBHCDHBNVf0EsBm4Osm5wLXAg1W1CXiw3aet2w6cB2wFbk2yqj3WbcBOYFO7bR1gXpKkPvQdCFV1uKq+1JZfAZ4G1gLbgD1tsz3AJW15G3BvVb1aVc8Ck8BFSc4BTq+qR6qqgLt6xkiSlsjqYTxIkg3A3wIeA8aq6jB0QyPJ2W2ztcCjPcOmWu21tjy7Ptd+dtI9kmBsbIxOp9PXfMfWwDUXzPQ1dlD9znlQ09PTI9v3qNjzyjCqnkf1HAKL1/PAgZDkrcDvAP+8qv7yBKf/51pRJ6gfW6zaDewGGB8fr4mJiZOeL8Atd+/jpoNDycKT9tzlEyPZb6fTod/f13JlzyvDqHr+2LVfWPJ9HnXn1rcsSs8DvcsoyQ/RDYO7q+rzrfzNdhqI9vNIq08B63uGrwNebPV1c9QlSUtokHcZBbgdeLqq/l3Pqv3Ajra8A9jXU9+e5LQkG+lePH68nV56Jcnm9phX9IyRJC2RQc6b/DTwi8DBJF9utV8FbgD2JrkSeB64DKCqDiXZCzxF9x1KV1fV623cVcCdwBrg/naTJC2hvgOhqv43c5//B9hynDG7gF1z1A8A5/c7F0nS4PyksiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnNKRMISbYmeSbJZJJrRz0fSVppTolASLIK+PfAB4FzgY8kOXe0s5KkleWUCATgImCyqr5eVd8D7gW2jXhOkrSirB71BJq1wAs996eAvz17oyQ7gZ3t7nSSZ/rc31nAS32OHUhuHMVegRH2PEL2vDKsuJ4/cONAPf/N4604VQIhc9TqmELVbmD3wDtLDlTV+KCPs5zY88pgzyvDYvV8qpwymgLW99xfB7w4orlI0op0qgTCHwCbkmxM8iZgO7B/xHOSpBXllDhlVFUzSf4p8N+BVcAdVXVoEXc58GmnZcieVwZ7XhkWpedUHXOqXpK0Ap0qp4wkSSNmIEiSgDd4IMz3dRjpurmt/2qS949insO0gJ4vb71+NcnvJ3nfKOY5TAv92pMkP5nk9SSXLuX8FsNCek4ykeTLSQ4l+Z9LPcdhWsD/67cl+S9JvtL6/fgo5jlMSe5IciTJk8dZP/znr6p6Q97oXpz+E+CdwJuArwDnztrmQ8D9dD8HsRl4bNTzXoKefwo4oy1/cCX03LPdQ8B/Ay4d9byX4N/57cBTwI+2+2ePet6L3O+vAje25R8BvgW8adRzH7DvnwXeDzx5nPVDf/56Ix8hLOTrMLYBd1XXo8Dbk5yz1BMdonl7rqrfr6pvt7uP0v3Mx3K20K89+QTwO8CRpZzcIllIz/8I+HxVPQ9QVcu574X0W8BfTxLgrXQDYWZppzlcVfUw3T6OZ+jPX2/kQJjr6zDW9rHNcnKy/VxJ9xXGcjZvz0nWAv8Q+O0lnNdiWsi/87uBM5J0kjyR5Iolm93wLaTf3wJ+gu4HWg8Cn6yq7y/N9EZm6M9fp8TnEBbJQr4OY0FfmbGMLLifJB+gGwh/d1FntPgW0vNvAJ+qqte7LyCXvYX0vBq4ENgCrAEeSfJoVf3xYk9uESyk34uBLwM/B/wY8ECS/1VVf7nIcxuloT9/vZEDYSFfh/FG+8qMBfWT5L3AZ4APVtWfL9HcFstCeh4H7m1hcBbwoSQzVfW7SzLD4Vvo/+2Xquo7wHeSPAy8D1iOgbCQfj8O3FDdk+uTSZ4Ffhx4fGmmOBJDf/56I58yWsjXYewHrmhX6zcDL1fV4aWe6BDN23OSHwU+D/ziMn21ONu8PVfVxqraUFUbgPuAf7KMwwAW9n97H/AzSVYneTPdbw9+eonnOSwL6fd5ukdDJBkD3gN8fUlnufSG/vz1hj1CqON8HUaSX2rrf5vuO04+BEwCf0X3VcaytcCe/xVwJnBre8U8U8v4myIX2PMbykJ6rqqnk3wR+CrwfeAzVTXn2xdPdQv8N/7XwJ1JDtI9lfKpqlrWX4md5B5gAjgryRRwPfBDsHjPX351hSQJeGOfMpIknQQDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJav4vbqQvPSgtD8YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"default.payment.next.month\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1s is: 22.07 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 1s is:\",4414/(15586+4414)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4448"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cust_id                         int64\n",
       "LIMIT_BAL                     float64\n",
       "SEX                           float64\n",
       "EDUCATION                     float64\n",
       "MARRIAGE                      float64\n",
       "AGE                           float64\n",
       "PAY_0                         float64\n",
       "PAY_2                         float64\n",
       "PAY_3                         float64\n",
       "PAY_4                         float64\n",
       "PAY_5                         float64\n",
       "PAY_6                         float64\n",
       "BILL_AMT1                     float64\n",
       "BILL_AMT2                     float64\n",
       "BILL_AMT3                     float64\n",
       "BILL_AMT4                     float64\n",
       "BILL_AMT5                     float64\n",
       "BILL_AMT6                     float64\n",
       "PAY_AMT1                      float64\n",
       "PAY_AMT2                      float64\n",
       "PAY_AMT3                      float64\n",
       "PAY_AMT4                      float64\n",
       "PAY_AMT5                      float64\n",
       "PAY_AMT6                      float64\n",
       "default.payment.next.month      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics= data.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in numerics:\n",
    "    data.loc[data[n].isna() == True,n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.iloc[:,1:-1]\n",
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using **F-value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    feature = np.array(X[column]).reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(feature)\n",
    "    feature_scaled = scaler.transform(feature)\n",
    "    X[column] = feature_scaled.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectKBest(score_func=f_classif, k=12)\n",
    "fs.fit_transform(X, Y)\n",
    "idx = fs.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.iloc[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparison(models,X_train,y_train,cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    \n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    AUC = []\n",
    "    Accuracy = []\n",
    "\n",
    "    for model in models:\n",
    "        AUC_v = np.round(cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv), 4)\n",
    "        AUC=np.append(AUC,AUC_v)\n",
    "        AUC_avg = round(AUC_v.mean(), 4)\n",
    "        Accuracy_v = np.round(cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv), 4)\n",
    "        Accuracy=np.append(Accuracy,Accuracy_v)\n",
    "        Accuracy_avg = round(Accuracy_v.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [AUC_avg,Accuracy_avg]\n",
    "    cv_accuracies.index = [\"AUC Score\",'Accuracy']\n",
    "    return cv_accuracies, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models to be tested\n",
    "LR = LogisticRegression()\n",
    "LDA_m = LDA()\n",
    "KNN = KNeighborsClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "SVM = LinearSVC()\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [LR, LDA_m, KNN,DT,SVM]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comparison, AUC = model_comparison(models, X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.7113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.7914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7087  0.7097  0.6989         0.6142  0.7113\n",
       "Accuracy                0.8027  0.8052  0.7896         0.7251  0.7914"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.columns  = ['Logistic Regression', 'LDA', 'KNN','Decision Tree',\"SVM\"]\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_comp = pd.DataFrame(np.reshape(AUC, (5,20)), index=comparison.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', \n",
    "                                                         '4th Fold','5th Fold', '6th Fold', '7th Fold', \n",
    "                                                         '8th Fold', '9th Fold', \n",
    "                                                         '10th Fold','11st Fold', '12nd Fold', '13rd Fold', \n",
    "                                                         '14th Fold','15th Fold', '16th Fold', '17th Fold', \n",
    "                                                         '18th Fold', '19th Fold', \n",
    "                                                         '20th Fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Fold</th>\n",
       "      <th>2nd Fold</th>\n",
       "      <th>3rd Fold</th>\n",
       "      <th>4th Fold</th>\n",
       "      <th>5th Fold</th>\n",
       "      <th>6th Fold</th>\n",
       "      <th>7th Fold</th>\n",
       "      <th>8th Fold</th>\n",
       "      <th>9th Fold</th>\n",
       "      <th>10th Fold</th>\n",
       "      <th>11st Fold</th>\n",
       "      <th>12nd Fold</th>\n",
       "      <th>13rd Fold</th>\n",
       "      <th>14th Fold</th>\n",
       "      <th>15th Fold</th>\n",
       "      <th>16th Fold</th>\n",
       "      <th>17th Fold</th>\n",
       "      <th>18th Fold</th>\n",
       "      <th>19th Fold</th>\n",
       "      <th>20th Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.6863</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.6837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.6763</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.6863</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.6858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.7204</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.6074</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.5913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.7265</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.6908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1st Fold  2nd Fold  3rd Fold  4th Fold  5th Fold  \\\n",
       "Logistic Regression    0.6735    0.7020    0.6863    0.7258    0.7212   \n",
       "LDA                    0.6763    0.6996    0.6863    0.7257    0.7232   \n",
       "KNN                    0.6710    0.7049    0.7246    0.6989    0.7393   \n",
       "Decision Tree          0.6069    0.6074    0.6088    0.6240    0.5838   \n",
       "SVM                    0.6724    0.7004    0.6875    0.7265    0.7248   \n",
       "\n",
       "                     6th Fold  7th Fold  8th Fold  9th Fold  10th Fold  \\\n",
       "Logistic Regression    0.6692    0.7133    0.7066    0.7342     0.7252   \n",
       "LDA                    0.6738    0.7135    0.7109    0.7343     0.7269   \n",
       "KNN                    0.6590    0.7204    0.7002    0.7337     0.6815   \n",
       "Decision Tree          0.5847    0.6088    0.6777    0.6320     0.6296   \n",
       "SVM                    0.6773    0.7141    0.7130    0.7367     0.7291   \n",
       "\n",
       "                     11st Fold  12nd Fold  13rd Fold  14th Fold  15th Fold  \\\n",
       "Logistic Regression     0.7336     0.6853     0.7050     0.7253     0.7110   \n",
       "LDA                     0.7347     0.6840     0.7068     0.7228     0.7125   \n",
       "KNN                     0.6972     0.6624     0.6854     0.6717     0.7094   \n",
       "Decision Tree           0.5980     0.6079     0.6105     0.5862     0.6384   \n",
       "SVM                     0.7383     0.6878     0.7109     0.7250     0.7088   \n",
       "\n",
       "                     16th Fold  17th Fold  18th Fold  19th Fold  20th Fold  \n",
       "Logistic Regression     0.7024     0.7424     0.7186     0.7095     0.6837  \n",
       "LDA                     0.7044     0.7449     0.7181     0.7089     0.6858  \n",
       "KNN                     0.6557     0.7579     0.6711     0.7295     0.7035  \n",
       "Decision Tree           0.6189     0.6202     0.5973     0.6508     0.5913  \n",
       "SVM                     0.7058     0.7475     0.7182     0.7110     0.6908  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.5)\n",
    "X_resampled,y_resampled = over.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12481\n",
       "1     6240\n",
       "Name: default.payment.next.month, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models to be tested\n",
    "LR = LogisticRegression()\n",
    "LDA_m = LDA()\n",
    "KNN = KNeighborsClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "SVM = LinearSVC()\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [LR, LDA_m, KNN,DT,SVM]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comparison_resampled, AUC = model_comparison(models, X_resampled, y_resampled, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.7113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.7914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7087  0.7097  0.6989         0.6142  0.7113\n",
       "Accuracy                0.8027  0.8052  0.7896         0.7251  0.7914"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.8014</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7166  0.7168  0.8014         0.6946  0.7188\n",
       "Accuracy                0.7545  0.7555  0.7586         0.7193  0.7546"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_resampled.columns  = ['Logistic Regression', 'LDA', 'KNN','Decision Tree',\"SVM\"]\n",
    "comparison_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cv\n",
    "cv = RepeatedStratifiedKFold(n_splits=20, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scoring matrices\n",
    "scoring = {\"AUC\": \"roc_auc\", \"F1\":\"f1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model initiation\n",
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['sag','saga', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(LR, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4000 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72081281        nan 0.72079139        nan 0.68981414 0.69206747\n",
      " 0.68254412 0.68213326 0.69486127        nan 0.72068306        nan\n",
      " 0.72081286        nan 0.72033807        nan        nan 0.72079144\n",
      " 0.68213616        nan 0.71918398 0.7104405  0.72079101 0.68217063\n",
      " 0.72050976        nan 0.72081291 0.70880718 0.72081283 0.71859364\n",
      " 0.68227204        nan 0.72081309        nan 0.7208126  0.72047642\n",
      " 0.72076285 0.72081273 0.5               nan 0.69954862 0.71913673\n",
      " 0.5        0.68837681 0.5        0.68230961 0.5               nan\n",
      "        nan        nan 0.5        0.72081294        nan 0.72079152\n",
      " 0.7089515  0.72079108        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.51683043        nan 0.51660722        nan 0.20899973 0.28044007\n",
      " 0.         0.         0.42908856        nan 0.51645996        nan\n",
      " 0.51682497        nan 0.51604817        nan        nan 0.51660722\n",
      " 0.                nan 0.51576698 0.43905726 0.51661257 0.\n",
      " 0.51641056        nan 0.51683602 0.50463309 0.51683043 0.51547986\n",
      " 0.                nan 0.51683034        nan 0.51682497 0.51574327\n",
      " 0.51650499 0.51683034 0.                nan 0.43099709 0.51561531\n",
      " 0.         0.10727199 0.         0.         0.005             nan\n",
      "        nan        nan 0.0025     0.51683043        nan 0.51662312\n",
      " 0.50312941 0.51662299        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fit the model with cv and hyperparameter\n",
    "LR_result = search.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5168360211738249\n",
      "Best Hyperparameters: {'C': 0.0006712014056111249, 'penalty': 'none', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % LR_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % LR_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7208129096811308"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_result.cv_results_[\"mean_test_AUC\"][LR_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0006712014056111249, penalty='none', solver='sag')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_final = LogisticRegression(C=0.0006712014056111249, penalty='none', solver='sag')\n",
    "LR_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_m = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd','lsqr','eigen']\n",
    "space['shrinkage']= np.arange(0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(LDA_m, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3800 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 583, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported\")\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.6967359         nan 0.70282181 0.70101682\n",
      " 0.69742956 0.70633661 0.68638425 0.69098622 0.687663          nan\n",
      " 0.68257917 0.7082717  0.70150015        nan 0.71493994 0.69813461\n",
      " 0.69348331 0.71230432        nan 0.70254755 0.68977965        nan\n",
      "        nan        nan        nan        nan 0.68351098 0.6967359\n",
      " 0.70008679 0.6901918  0.6925056  0.7082717         nan 0.70458748\n",
      " 0.70397483 0.69835035 0.70560046 0.69379592 0.69348331        nan\n",
      " 0.69627755 0.71611589 0.70669917        nan        nan 0.6985711\n",
      " 0.71405191 0.69469356        nan 0.68493862        nan 0.69742956\n",
      "        nan 0.70175169 0.7078886         nan 0.69410655 0.69603235]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.54835337        nan 0.5318782  0.53529204\n",
      " 0.54632184 0.53425107 0.56477297 0.56121259 0.56460276        nan\n",
      " 0.56657108 0.53433686 0.5329445         nan 0.51771147 0.54408002\n",
      " 0.55734338 0.52750469        nan 0.53189117 0.56091845        nan\n",
      "        nan        nan        nan        nan 0.56627321 0.54835337\n",
      " 0.53928012 0.56162615 0.55842889 0.53433686        nan 0.53377458\n",
      " 0.5329559  0.54362535 0.53429155 0.55725671 0.55734338        nan\n",
      " 0.55008672 0.51410854 0.53423402        nan        nan 0.54318401\n",
      " 0.52112859 0.55644168        nan 0.56490971        nan 0.54632184\n",
      "        nan 0.53262015 0.53453167        nan 0.55710038 0.55039473]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LDA_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5665710790846897\n",
      "Best Hyperparameters: {'solver': 'eigen', 'shrinkage': 0.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6825791712278106"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % LDA_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % LDA_result.best_params_)\n",
    "LDA_result.cv_results_[\"mean_test_AUC\"][LDA_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(shrinkage=0.99, solver='eigen')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_final = LDA(solver='eigen',shrinkage=0.99)\n",
    "LDA_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['n_neighbors'] = [2,4,8,16,20,30,40,50,60]\n",
    "space['p']=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(KNN, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 18 is smaller than n_iter=60. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "KNN_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5997507117682961\n",
      "Best Hyperparameters: {'p': 1, 'n_neighbors': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8022896891436555"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % KNN_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % KNN_result.best_params_)\n",
    "KNN_result.cv_results_[\"mean_test_AUC\"][KNN_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8, p=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_final = KNeighborsClassifier(n_neighbors=8,p=1)\n",
    "KNN_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['criterion'] = [\"gini\",\"entropy\"]\n",
    "space['splitter']=[\"best\", \"random\"]\n",
    "space['min_samples_leaf']=[1,2,3,4,5,6,7,8,9,10]\n",
    "space['min_weight_fraction_leaf']=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "space['max_features']=[\"auto\",\"log2\",\"sqrt\",None]\n",
    "space['max_leaf_nodes']=[None,10,20,30,40,50,60,70,80,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(DT, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5600 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 304, in fit\n",
      "    raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "ValueError: min_weight_fraction_leaf must in [0, 0.5]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.55518135 0.58504086 0.50100305 0.50800754        nan\n",
      " 0.55980566        nan        nan 0.70597288        nan        nan\n",
      " 0.5        0.56944119        nan        nan        nan 0.5\n",
      "        nan        nan 0.64043994        nan        nan        nan\n",
      " 0.50328753 0.58473866 0.63946267        nan 0.50033654        nan\n",
      "        nan 0.56953793        nan        nan 0.55740289 0.66231083\n",
      " 0.50839863 0.50854835        nan 0.56986515 0.50088301 0.50778132\n",
      " 0.58581396 0.58589916 0.58589916        nan 0.56491394        nan\n",
      " 0.56741358        nan 0.63578765        nan 0.66280636 0.63468162\n",
      "        nan 0.50546074 0.52649127        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.15407418 0.         0.         0.                nan\n",
      " 0.17222593        nan        nan 0.48551333        nan        nan\n",
      " 0.         0.                nan        nan        nan 0.\n",
      "        nan        nan 0.20111166        nan        nan        nan\n",
      " 0.         0.         0.18673533        nan 0.                nan\n",
      "        nan 0.                nan        nan 0.08418388 0.43007076\n",
      " 0.         0.                nan 0.         0.         0.\n",
      " 0.         0.         0.                nan 0.09913022        nan\n",
      " 0.                nan 0.17435431        nan 0.43285513 0.17206789\n",
      "        nan 0.         0.                nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DT_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.485513327379842\n",
      "Best Hyperparameters: {'splitter': 'best', 'min_weight_fraction_leaf': 0.1, 'min_samples_leaf': 9, 'max_leaf_nodes': None, 'max_features': 'auto', 'criterion': 'gini'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7059728783078566"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1 score: %s' % DT_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % DT_result.best_params_)\n",
    "DT_result.cv_results_[\"mean_test_AUC\"][DT_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', min_samples_leaf=9,\n",
       "                       min_weight_fraction_leaf=0.1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_final = DecisionTreeClassifier(splitter=\"best\",min_weight_fraction_leaf=0.1,min_samples_leaf=9,max_leaf_nodes=None,max_features=\"auto\",criterion=\"gini\")\n",
    "DT_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['C'] = [0.001, 0.01, 10, 100, 1000]\n",
    "space['penalty']=[\"l1\", \"l2\"]\n",
    "space['loss']=[\"hinge\", \"squared_hinge\"]\n",
    "space['class_weight']=[None,\"balanced\"]\n",
    "space[\"max_iter\"]=[2000,2500,3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(SVM, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5800 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72003075        nan 0.71916179 0.70948762 0.68587925        nan\n",
      " 0.70670589 0.71918292        nan        nan 0.68938894 0.68886407\n",
      "        nan        nan 0.71544243        nan        nan 0.7005584\n",
      " 0.71996649        nan        nan 0.68512132 0.71918749        nan\n",
      " 0.68568612        nan 0.70670596        nan 0.72003406        nan\n",
      " 0.70670594        nan        nan        nan        nan 0.68813181\n",
      "        nan        nan        nan 0.69459899 0.71065622 0.69211122\n",
      "        nan 0.71446886 0.69893002 0.71996657 0.71746258 0.71751031\n",
      "        nan 0.71916176 0.71708914        nan 0.69459905        nan\n",
      "        nan 0.7094815         nan        nan 0.68512122        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.56668231        nan 0.50843767 0.43716326 0.53928319        nan\n",
      " 0.48760069 0.50855724        nan        nan 0.52499929 0.52972348\n",
      "        nan        nan 0.56211159        nan        nan 0.29618526\n",
      " 0.56683821        nan        nan 0.49818049 0.50843269        nan\n",
      " 0.53918674        nan 0.48760069        nan 0.56698909        nan\n",
      " 0.48760069        nan        nan        nan        nan 0.53971678\n",
      "        nan        nan        nan 0.54423202 0.45539585 0.00891669\n",
      "        nan 0.55816387 0.56309645 0.56683821 0.57911635 0.57926549\n",
      "        nan 0.50843767 0.57829449        nan 0.54423202        nan\n",
      "        nan 0.36497552        nan        nan 0.49817806        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SVM_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5792654913970811\n",
      "Best Hyperparameters: {'penalty': 'l2', 'max_iter': 2000, 'loss': 'hinge', 'class_weight': 'balanced', 'C': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7175103122534517"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % SVM_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % SVM_result.best_params_)\n",
    "SVM_result.cv_results_[\"mean_test_AUC\"][SVM_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100, class_weight='balanced', loss='hinge', max_iter=2000)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_final = LinearSVC(penalty=\"l2\",loss='hinge',class_weight='balanced',C=100,max_iter= 2000)\n",
    "SVM_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LR_result, LDA_result, KNN_result,DT_result,SVM_result]\n",
    "def train_auc (models):\n",
    "    measures = pd.DataFrame()\n",
    "    names = ['Logisitc Regression', 'LDA', \"KNN\",'Decision Tree',\"SVM\"]\n",
    "    for model,i in zip(models,names): \n",
    "        measures[i] = [np.round(model.cv_results_[\"mean_test_AUC\"][model.best_index_],4),np.round(model.best_score_,4)]\n",
    "\n",
    "    measures.index = ['Train AUC Score',\"Train F-1 score\"]\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logisitc Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train AUC Score</th>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F-1 score</th>\n",
       "      <td>0.5168</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.5793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Logisitc Regression     LDA     KNN  Decision Tree     SVM\n",
       "Train AUC Score               0.7208  0.6826  0.8023         0.7060  0.7175\n",
       "Train F-1 score               0.5168  0.5666  0.5998         0.4855  0.5793"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_auc(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: Logisitc Regression\n",
      "[[2893  212]\n",
      " [ 547  348]]\n",
      "confusion matrix: LDA\n",
      "[[2644  461]\n",
      " [ 408  487]]\n",
      "confusion matrix: KNN\n",
      "[[2751  354]\n",
      " [ 504  391]]\n",
      "confusion matrix: Decision Tree\n",
      "[[2847  258]\n",
      " [ 563  332]]\n",
      "confusion matrix: SVM\n",
      "[[2652  453]\n",
      " [ 434  461]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model_name = ['Logisitc Regression', 'LDA', \"KNN\",'Decision Tree',\"SVM\"]\n",
    "for model,name in zip(models,model_name): \n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"confusion matrix:\",name)\n",
    "    print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_comparison(models, X_test, y_test):\n",
    "    measures = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(X_test)\n",
    "        AUC = round(roc_auc_score(y_test, predictions), 4)\n",
    "        F1 = round(f1_score(y_test, predictions), 4)\n",
    "        measures[str(model)] = [AUC, F1]\n",
    "    measures.index = ['Test AUC Score', 'Test F-1 score']\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = final_comparison([LR_final, LDA_final, KNN_final,DT_final,SVM_final], X_test, y_test)\n",
    "benchmark.columns  = ['Logisitc Regression', 'LDA', \"KNN\",'Decision Tree',\"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logisitc Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test AUC Score</th>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.6851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test F-1 score</th>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>0.5089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Logisitc Regression     LDA     KNN  Decision Tree     SVM\n",
       "Test AUC Score               0.6603  0.6978  0.6614         0.6475  0.6851\n",
       "Test F-1 score               0.4784  0.5285  0.4768         0.4547  0.5089"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81e0b57edd17c3833f38e5d4db6db81e2c0f982e51ee4890d9e870805c7d8a75"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
