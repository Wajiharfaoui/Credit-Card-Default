{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(models,model_name,X_train,y_train,cv):\n",
    "    \n",
    "    measures = pd.DataFrame()\n",
    "    AUC_test = []\n",
    "    AUC_train = []\n",
    "    Score_test = []\n",
    "    Score_train =[]\n",
    "\n",
    "    for model,name in zip(models,model_name): \n",
    "        AUC_v = cross_validate(model, X_train, y_train, scoring='roc_auc', cv=cv,return_train_score=True)\n",
    "        AUC_test=AUC_v[\"test_score\"].mean()\n",
    "        AUC_train=AUC_v[\"train_score\"].mean()\n",
    "        Score_v = cross_validate(model, X_train, y_train, scoring='f1', cv=cv,return_train_score=True)\n",
    "        Score_test=Score_v[\"test_score\"].mean()\n",
    "        Score_train=Score_v[\"train_score\"].mean()\n",
    "        measures[name] = [AUC_test, Score_test,AUC_train,Score_train]\n",
    "        measures.index =['Test AUC Score', 'Test F-1 score','Train AUC Score', 'Train F-1 score']\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparison(models,X_train,y_train,cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    \n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    AUC = []\n",
    "    Accuracy = []\n",
    "\n",
    "    for model in models:\n",
    "        AUC_v = np.round(cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv,), 4)\n",
    "        AUC=np.append(AUC,AUC_v)\n",
    "        AUC_avg = round(AUC_v.mean(), 4)\n",
    "        Accuracy_v = np.round(cross_val_score(model, X_train, y_train, scoring='f1', cv=cv), 4)\n",
    "        Accuracy=np.append(Accuracy,Accuracy_v)\n",
    "        Accuracy_avg = round(Accuracy_v.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [AUC_avg,Accuracy_avg]\n",
    "    cv_accuracies.index = [\"AUC Score\",'Accuracy']\n",
    "    return cv_accuracies, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploratory and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data\n",
    "data = pd.read_csv('./Data/credit_default_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18895</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25559.0</td>\n",
       "      <td>26134.0</td>\n",
       "      <td>26715.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25102</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140387.0</td>\n",
       "      <td>128112.0</td>\n",
       "      <td>115514.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28867</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26038.0</td>\n",
       "      <td>28607.0</td>\n",
       "      <td>27997.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1842</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72391.0</td>\n",
       "      <td>61298.0</td>\n",
       "      <td>62193.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3371</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0    18895    70000.0  1.0        3.0       2.0  34.0    0.0    0.0    0.0   \n",
       "1    25102   390000.0  2.0        2.0       2.0  26.0    2.0    2.0    2.0   \n",
       "2    28867    60000.0  1.0        1.0       2.0  27.0    0.0    0.0    0.0   \n",
       "3     1842   140000.0  2.0        2.0       1.0  55.0    0.0    0.0    0.0   \n",
       "4     3371    50000.0  1.0        1.0       2.0  29.0    2.0    2.0    2.0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0    0.0  ...    25559.0    26134.0    26715.0    1700.0    1500.0    2000.0   \n",
       "1    0.0  ...   140387.0   128112.0   115514.0    5000.0    3000.0    5000.0   \n",
       "2    0.0  ...    26038.0    28607.0    27997.0    1378.0    1406.0    3000.0   \n",
       "3    0.0  ...    72391.0    61298.0    62193.0    4200.0    2822.0    2336.0   \n",
       "4    0.0  ...     1047.0        0.0        0.0    3000.0       0.0    1000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0    1000.0    1000.0    2000.0                           0  \n",
       "1    4548.0    4100.0    3300.0                           0  \n",
       "2    3000.0       0.0     923.0                           1  \n",
       "3    2588.0    2250.0    2491.0                           0  \n",
       "4       0.0       0.0       0.0                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"AGE\"] = pd.to_numeric(data[\"AGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"SEX\"]==1,\"SEX\"]=\"Male\"\n",
    "data.loc[data[\"SEX\"]==2,\"SEX\"]=\"Female\"\n",
    "data.loc[data[\"EDUCATION\"]==1,\"EDUCATION\"]=\"G_School\"\n",
    "data.loc[data[\"EDUCATION\"]==2,\"EDUCATION\"]=\"Uni\"\n",
    "data.loc[data[\"EDUCATION\"]==3,\"EDUCATION\"]=\"High_School\"\n",
    "data.loc[data[\"EDUCATION\"]==4,\"EDUCATION\"]=\"Other_edu\"\n",
    "data.loc[data[\"EDUCATION\"]==5,\"EDUCATION\"]=\"unknown\"\n",
    "data.loc[(data[\"EDUCATION\"]==6) |(data[\"EDUCATION\"]==0),\"EDUCATION\"]=\"unknown\"\n",
    "data.loc[data[\"MARRIAGE\"]==1,\"MARRIAGE\"]=\"married\"\n",
    "data.loc[data[\"MARRIAGE\"]==2,\"MARRIAGE\"]=\"single\"\n",
    "data.loc[(data[\"MARRIAGE\"]==3) |(data[\"MARRIAGE\"]==0),\"MARRIAGE\"]=\"Other_status\"\n",
    "data.loc[(data[\"AGE\"]>=21) & (data[\"AGE\"]<=39),\"AGE_Cate\"]=\"Young\"\n",
    "data.loc[(data[\"AGE\"]>=40) & (data[\"AGE\"]<=59),\"AGE_Cate\"]=\"Adult\"\n",
    "data.loc[data[\"AGE\"]>=60,\"AGE_Cate\"]=\"Old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(data[\"SEX\"],drop_first=True)\n",
    "education_dummy = pd.get_dummies(data[\"EDUCATION\"],drop_first=True)\n",
    "mariage_dummy = pd.get_dummies(data[\"MARRIAGE\"],drop_first=True)\n",
    "age_dummy = pd.get_dummies(data[\"AGE_Cate\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,sex_dummy,education_dummy,mariage_dummy,age_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>AGE_Cate</th>\n",
       "      <th>Male</th>\n",
       "      <th>High_School</th>\n",
       "      <th>Other_edu</th>\n",
       "      <th>Uni</th>\n",
       "      <th>unknown</th>\n",
       "      <th>married</th>\n",
       "      <th>single</th>\n",
       "      <th>Old</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18895</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>High_School</td>\n",
       "      <td>single</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25102</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Uni</td>\n",
       "      <td>single</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28867</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>G_School</td>\n",
       "      <td>single</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1842</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Uni</td>\n",
       "      <td>married</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3371</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>G_School</td>\n",
       "      <td>single</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  LIMIT_BAL     SEX    EDUCATION MARRIAGE   AGE  PAY_0  PAY_2  \\\n",
       "0    18895    70000.0    Male  High_School   single  34.0    0.0    0.0   \n",
       "1    25102   390000.0  Female          Uni   single  26.0    2.0    2.0   \n",
       "2    28867    60000.0    Male     G_School   single  27.0    0.0    0.0   \n",
       "3     1842   140000.0  Female          Uni  married  55.0    0.0    0.0   \n",
       "4     3371    50000.0    Male     G_School   single  29.0    2.0    2.0   \n",
       "\n",
       "   PAY_3  PAY_4  ...  AGE_Cate  Male  High_School  Other_edu  Uni  unknown  \\\n",
       "0    0.0    0.0  ...     Young     1            1          0    0        0   \n",
       "1    2.0    0.0  ...     Young     0            0          0    1        0   \n",
       "2    0.0    0.0  ...     Young     1            0          0    0        0   \n",
       "3    0.0    0.0  ...     Adult     0            0          0    1        0   \n",
       "4    2.0    0.0  ...     Young     1            0          0    0        0   \n",
       "\n",
       "   married  single  Old  Young  \n",
       "0        0       1    0      1  \n",
       "1        0       1    0      1  \n",
       "2        0       1    0      1  \n",
       "3        1       0    0      0  \n",
       "4        0       1    0      1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cust_id', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default.payment.next.month', 'AGE_Cate', 'Male', 'High_School',\n",
       "       'Other_edu', 'Uni', 'unknown', 'married', 'single', 'Old', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"default.payment.next.month\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7793\n",
       "1    0.2207\n",
       "Name: default.payment.next.month, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"default.payment.next.month\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bill_Total']= data[list(data.filter(regex='BILL_'))].mean(axis=1)\n",
    "data['Pay_AMT_Total']= data[list(data.filter(regex='PAY_AMT'))].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cust_id', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default.payment.next.month', 'AGE_Cate', 'Male', 'High_School',\n",
       "       'Other_edu', 'Uni', 'unknown', 'married', 'single', 'Old', 'Young',\n",
       "       'Bill_Total', 'Pay_AMT_Total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(columns=['cust_id',\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",'BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\"AGE_Cate\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pd.DataFrame(data.loc[:,['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'Male', 'High_School', 'Other_edu', 'Uni',\n",
    "       'unknown', 'married', 'single', 'Old', 'Young', 'Bill_Total',\n",
    "       'Pay_AMT_Total']])\n",
    "Y = data.loc[:,'default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    feature = np.array(X[column]).reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(feature)\n",
    "    feature_scaled = scaler.transform(feature)\n",
    "    X[column]= pd.DataFrame(feature_scaled.reshape(1,-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using **F-value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection \n",
    "fs = SelectKBest(score_func=f_classif, k=15)\n",
    "fs.fit_transform(X, Y)\n",
    "idx = fs.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>Male</th>\n",
       "      <th>High_School</th>\n",
       "      <th>Other_edu</th>\n",
       "      <th>Uni</th>\n",
       "      <th>unknown</th>\n",
       "      <th>married</th>\n",
       "      <th>single</th>\n",
       "      <th>Pay_AMT_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18615</th>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.082997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18616</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18617</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18618</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18619</th>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18620 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  Male  High_School  \\\n",
       "0       0.060606    0.2    0.2    0.2    0.2    0.2    0.2   1.0          1.0   \n",
       "1       0.383838    0.4    0.4    0.4    0.2    0.2    0.2   0.0          0.0   \n",
       "2       0.050505    0.2    0.2    0.2    0.2    0.2    0.4   1.0          0.0   \n",
       "3       0.131313    0.2    0.2    0.2    0.2    0.2    0.2   0.0          0.0   \n",
       "4       0.040404    0.4    0.4    0.4    0.2    0.2    0.0   1.0          0.0   \n",
       "...          ...    ...    ...    ...    ...    ...    ...   ...          ...   \n",
       "18615   0.494949    0.3    0.0    0.1    0.2    0.2    0.2   1.0          0.0   \n",
       "18616   0.020202    0.2    0.2    0.2    0.2    0.2    0.2   1.0          1.0   \n",
       "18617   0.010101    0.3    0.4    0.6    0.5    0.4    0.4   1.0          0.0   \n",
       "18618   0.232323    0.2    0.2    0.2    0.2    0.2    0.2   1.0          0.0   \n",
       "18619   0.121212    0.2    0.2    0.2    0.2    0.2    0.2   0.0          0.0   \n",
       "\n",
       "       Other_edu  Uni  unknown  married  single  Pay_AMT_Total  \n",
       "0            0.0  0.0      0.0      0.0     1.0       0.003976  \n",
       "1            0.0  1.0      0.0      0.0     1.0       0.010781  \n",
       "2            0.0  0.0      0.0      0.0     1.0       0.004195  \n",
       "3            0.0  1.0      0.0      1.0     0.0       0.007211  \n",
       "4            0.0  0.0      0.0      0.0     1.0       0.001728  \n",
       "...          ...  ...      ...      ...     ...            ...  \n",
       "18615        0.0  1.0      0.0      0.0     1.0       0.082997  \n",
       "18616        0.0  0.0      0.0      0.0     1.0       0.005192  \n",
       "18617        0.0  1.0      0.0      0.0     1.0       0.001080  \n",
       "18618        0.0  1.0      0.0      0.0     1.0       0.070039  \n",
       "18619        0.0  1.0      0.0      1.0     0.0       0.011717  \n",
       "\n",
       "[18620 rows x 15 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create the models to be tested\n",
    "LR = LogisticRegression()\n",
    "LDA_m = LDA()\n",
    "KNN = KNeighborsClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "SVM = LinearSVC()\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [LR, LDA_m, KNN,DT,SVM]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comparison, AUC = model_comparison(models, X,Y, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8073</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7124  0.7111  0.6958         0.6081  0.7129\n",
       "Accuracy                0.8073  0.8096  0.7917         0.7221  0.7966"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.columns  = ['Logistic Regression', 'LDA', 'KNN','Decision Tree',\"SVM\"]\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_comp = pd.DataFrame(np.reshape(AUC, (5,20)), index=comparison.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', \n",
    "                                                         '4th Fold','5th Fold', '6th Fold', '7th Fold', \n",
    "                                                         '8th Fold', '9th Fold', \n",
    "                                                         '10th Fold','11st Fold', '12nd Fold', '13rd Fold', \n",
    "                                                         '14th Fold','15th Fold', '16th Fold', '17th Fold', \n",
    "                                                         '18th Fold', '19th Fold', \n",
    "                                                         '20th Fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Fold</th>\n",
       "      <th>2nd Fold</th>\n",
       "      <th>3rd Fold</th>\n",
       "      <th>4th Fold</th>\n",
       "      <th>5th Fold</th>\n",
       "      <th>6th Fold</th>\n",
       "      <th>7th Fold</th>\n",
       "      <th>8th Fold</th>\n",
       "      <th>9th Fold</th>\n",
       "      <th>10th Fold</th>\n",
       "      <th>11st Fold</th>\n",
       "      <th>12nd Fold</th>\n",
       "      <th>13rd Fold</th>\n",
       "      <th>14th Fold</th>\n",
       "      <th>15th Fold</th>\n",
       "      <th>16th Fold</th>\n",
       "      <th>17th Fold</th>\n",
       "      <th>18th Fold</th>\n",
       "      <th>19th Fold</th>\n",
       "      <th>20th Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.7118</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.6852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.7116</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.6828</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.7499</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.6629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.6078</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.6224</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.6017</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.6894</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>0.7013</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.6972</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.6877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1st Fold  2nd Fold  3rd Fold  4th Fold  5th Fold  \\\n",
       "Logistic Regression    0.7118    0.6969    0.6972    0.7141    0.7030   \n",
       "LDA                    0.7116    0.6949    0.7044    0.7143    0.7083   \n",
       "KNN                    0.6876    0.6769    0.6626    0.7131    0.7303   \n",
       "Decision Tree          0.6351    0.6461    0.6275    0.6379    0.6392   \n",
       "SVM                    0.7149    0.6967    0.7097    0.7178    0.7115   \n",
       "\n",
       "                     6th Fold  7th Fold  8th Fold  9th Fold  10th Fold  \\\n",
       "Logistic Regression    0.7763    0.6873    0.6836    0.7047     0.7229   \n",
       "LDA                    0.7874    0.6881    0.6828    0.7053     0.7228   \n",
       "KNN                    0.7499    0.6851    0.6582    0.6870     0.7059   \n",
       "Decision Tree          0.6482    0.5924    0.5931    0.6092     0.6078   \n",
       "SVM                    0.7915    0.6894    0.6831    0.7076     0.7235   \n",
       "\n",
       "                     11st Fold  12nd Fold  13rd Fold  14th Fold  15th Fold  \\\n",
       "Logistic Regression     0.7090     0.6947     0.7333     0.6927     0.6967   \n",
       "LDA                     0.7088     0.6986     0.7367     0.6966     0.6985   \n",
       "KNN                     0.6883     0.7232     0.7002     0.6925     0.6718   \n",
       "Decision Tree           0.5912     0.5865     0.6224     0.6180     0.6017   \n",
       "SVM                     0.7058     0.7013     0.7386     0.6979     0.6972   \n",
       "\n",
       "                     16th Fold  17th Fold  18th Fold  19th Fold  20th Fold  \n",
       "Logistic Regression     0.6845     0.6986     0.6985     0.7186     0.6852  \n",
       "LDA                     0.6864     0.6969     0.6978     0.7236     0.6847  \n",
       "KNN                     0.6612     0.6584     0.6859     0.7410     0.6629  \n",
       "Decision Tree           0.5874     0.6044     0.6172     0.6307     0.6208  \n",
       "SVM                     0.6855     0.6993     0.6994     0.7229     0.6877  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.6)\n",
    "X_resampled,y_resampled = over.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14490\n",
       "1     8694\n",
       "Name: default.payment.next.month, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models to be tested\n",
    "LR = LogisticRegression()\n",
    "LDA_m = LDA()\n",
    "KNN = KNeighborsClassifier()\n",
    "DT = DecisionTreeClassifier()\n",
    "SVM = LinearSVC()\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [LR, LDA_m, KNN,DT,SVM]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comparison_resampled, AUC = model_comparison(models, X_resampled, y_resampled, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8073</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7124  0.7111  0.6958         0.6081  0.7129\n",
       "Accuracy                0.8073  0.8096  0.7917         0.7221  0.7966"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC Score</th>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.7084</td>\n",
       "      <td>0.7178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression     LDA     KNN  Decision Tree     SVM\n",
       "AUC Score               0.7169  0.7164  0.8029         0.7084  0.7178\n",
       "Accuracy                0.7337  0.7338  0.7469         0.7221  0.7340"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_resampled.columns  = ['Logistic Regression', 'LDA', 'KNN','Decision Tree',\"SVM\"]\n",
    "comparison_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cv\n",
    "cv = RepeatedStratifiedKFold(n_splits=20, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scoring matrices\n",
    "scoring = {\"AUC\": \"roc_auc\", \"F1\":\"f1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model initiation\n",
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['sag','saga', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(LR, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4000 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.71991575        nan 0.71991448        nan 0.69135216 0.6940926\n",
      " 0.66100523 0.64679753 0.70811651        nan 0.71985634        nan\n",
      " 0.71991217        nan 0.71955246        nan        nan 0.71991435\n",
      " 0.64694015        nan 0.71864525 0.70961706 0.71991457 0.64854588\n",
      " 0.71969289        nan 0.71991437 0.71108507 0.71991483 0.71820789\n",
      " 0.65241916        nan 0.71991613        nan 0.71991627 0.71981314\n",
      " 0.71989845 0.71991549 0.68859847        nan 0.70273431 0.71862455\n",
      " 0.68849247 0.68916896 0.5        0.653779   0.5               nan\n",
      "        nan        nan 0.5        0.71991472        nan 0.71991419\n",
      " 0.71086908 0.71991432        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.72077886        nan 0.72077633        nan 0.69191361 0.69468958\n",
      " 0.66179795 0.64757741 0.70874101        nan 0.72070593        nan\n",
      " 0.7207776         nan 0.72041733        nan        nan 0.72077635\n",
      " 0.64771819        nan 0.71951358 0.71004443 0.72077634 0.64931817\n",
      " 0.72056017        nan 0.72077802 0.71177731 0.72077848 0.71907304\n",
      " 0.65320076        nan 0.72077751        nan 0.72077796 0.72063096\n",
      " 0.72075834 0.72077826 0.68865751        nan 0.70344609 0.71948759\n",
      " 0.68864724 0.6897174  0.5        0.65455963 0.5               nan\n",
      "        nan        nan 0.5        0.72077896        nan 0.72077633\n",
      " 0.71150352 0.72077634        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [5.49748393e-01            nan 5.49787945e-01            nan\n",
      " 3.86941663e-01 4.36404891e-01 0.00000000e+00 0.00000000e+00\n",
      " 4.81379738e-01            nan 5.49640793e-01            nan\n",
      " 5.49781622e-01            nan 5.49731413e-01            nan\n",
      "            nan 5.49787945e-01 0.00000000e+00            nan\n",
      " 5.49058493e-01 5.27351705e-01 5.49787945e-01 0.00000000e+00\n",
      " 5.49665269e-01            nan 5.49799082e-01 5.44846701e-01\n",
      " 5.49848409e-01 5.48437280e-01 0.00000000e+00            nan\n",
      " 5.49800653e-01            nan 5.49827547e-01 5.49616108e-01\n",
      " 5.49740267e-01 5.49769449e-01 1.71861424e-03            nan\n",
      " 5.22819387e-01 5.49008165e-01 1.60340760e-04 3.49100704e-01\n",
      " 0.00000000e+00 0.00000000e+00 5.44883867e-03            nan\n",
      "            nan            nan 0.00000000e+00 5.49819006e-01\n",
      "            nan 5.49787945e-01 5.43929456e-01 5.49787945e-01\n",
      "            nan            nan            nan            nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [5.50566027e-01            nan 5.50557562e-01            nan\n",
      " 3.87573703e-01 4.37400556e-01 0.00000000e+00 0.00000000e+00\n",
      " 4.82061360e-01            nan 5.50497670e-01            nan\n",
      " 5.50556970e-01            nan 5.50559031e-01            nan\n",
      "            nan 5.50556928e-01 0.00000000e+00            nan\n",
      " 5.49886664e-01 5.28143216e-01 5.50556503e-01 0.00000000e+00\n",
      " 5.50513366e-01            nan 5.50559447e-01 5.45319196e-01\n",
      " 5.50552686e-01 5.49283021e-01 0.00000000e+00            nan\n",
      " 5.50540020e-01            nan 5.50542884e-01 5.50453611e-01\n",
      " 5.50536102e-01 5.50541839e-01 1.88936445e-03            nan\n",
      " 5.23763920e-01 5.49841992e-01 1.19745346e-04 3.49999791e-01\n",
      " 0.00000000e+00 0.00000000e+00 5.45484563e-03            nan\n",
      "            nan            nan 0.00000000e+00 5.50550853e-01\n",
      "            nan 5.50556583e-01 5.44416606e-01 5.50555815e-01\n",
      "            nan            nan            nan            nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fit the model with cv and hyperparameter\n",
    "LR_result = search.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5498484087392389\n",
      "Best Hyperparameters: {'C': 0.0282759467303296, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.7199148293080748\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % LR_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % LR_result.best_params_)\n",
    "print(LR_result.cv_results_[\"mean_test_AUC\"][LR_result.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_final = LogisticRegression(C=15.245533915454045, penalty='l1', solver='saga')\n",
    "LR_final=LR_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_m = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd','lsqr','eigen']\n",
    "space['shrinkage']= np.arange(0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(LDA_m, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3800 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 583, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported\")\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.67963717        nan 0.68894996 0.68648535\n",
      " 0.68080915 0.69317048 0.65952232 0.66914145 0.66275473        nan\n",
      " 0.64744196 0.69533867 0.68716503        nan 0.70818693 0.68192894\n",
      " 0.67379123 0.70113275        nan 0.68858803 0.66697027        nan\n",
      "        nan        nan        nan        nan 0.65093735 0.67963717\n",
      " 0.68510079 0.66770707 0.67188638 0.69533867        nan 0.69118819\n",
      " 0.69043006 0.68230119 0.69235615 0.67437038 0.67379123        nan\n",
      " 0.67881101 0.71251941 0.69358918        nan        nan 0.68266778\n",
      " 0.70522707 0.67598554        nan 0.655593          nan 0.68080915\n",
      "        nan 0.68751426 0.69489698        nan 0.67492776 0.67837415]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.68023909        nan 0.68950169 0.68704623\n",
      " 0.68139806 0.69375699 0.66032455 0.66987061 0.66353956        nan\n",
      " 0.64821121 0.69594602 0.68773268        nan 0.70901421 0.68251805\n",
      " 0.67445313 0.70181779        nan 0.68914229 0.6677192         nan\n",
      "        nan        nan        nan        nan 0.65171593 0.68023909\n",
      " 0.68567256 0.66845531 0.67257327 0.69594602        nan 0.69174676\n",
      " 0.69097749 0.68288279 0.6929379  0.67503122 0.67445313        nan\n",
      " 0.67942132 0.71341771 0.69417632        nan        nan 0.68324611\n",
      " 0.70599351 0.67663841        nan 0.65639499        nan 0.68139806\n",
      "        nan 0.68807729 0.69549407        nan 0.67558655 0.67899304]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45074748        nan 0.47896819 0.47027156\n",
      " 0.45426566 0.49166093 0.44447898 0.43817788 0.44018858        nan\n",
      " 0.45310946 0.4997441  0.47291577        nan 0.54293665 0.4574575\n",
      " 0.44536528 0.52609743        nan 0.47788593 0.43733924        nan\n",
      "        nan        nan        nan        nan 0.45340107 0.45074748\n",
      " 0.46688337 0.43724436 0.44401642 0.4997441         nan 0.4862183\n",
      " 0.48355582 0.45862124 0.48928061 0.44551298 0.44536528        nan\n",
      " 0.44898468 0.54551666 0.49277789        nan        nan 0.46010057\n",
      " 0.53817941 0.44498627        nan 0.44833272        nan 0.45426566\n",
      "        nan 0.47387318 0.49745222        nan 0.4456156  0.44820386]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.45147969        nan 0.47999425 0.47098336\n",
      " 0.45498022 0.49270453 0.4455416  0.43940858 0.44102189        nan\n",
      " 0.45449193 0.5002407  0.47342877        nan 0.54342763 0.45858039\n",
      " 0.44714617 0.52695206        nan 0.47885045 0.43816983        nan\n",
      "        nan        nan        nan        nan 0.4542879  0.45147969\n",
      " 0.46749565 0.43818708 0.44521403 0.5002407         nan 0.48710573\n",
      " 0.4846253  0.4597336  0.49010014 0.44720224 0.44714617        nan\n",
      " 0.4496218  0.54608772 0.49386863        nan        nan 0.46095416\n",
      " 0.53893546 0.44642175        nan 0.449402          nan 0.45498022\n",
      "        nan 0.47472805 0.49805671        nan 0.44713057 0.44867806]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LDA_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5455166606499169\n",
      "Best Hyperparameters: {'solver': 'lsqr', 'shrinkage': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % LDA_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % LDA_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_final = LDA(solver='lsqr',shrinkage=0.01)\n",
    "LDA_final=LDA_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['n_neighbors'] = [2,4,8,16,20,30,40,50,60]\n",
    "space['p']=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(KNN, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 18 is smaller than n_iter=60. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "KNN_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.6292657437386413\n",
      "Best Hyperparameters: {'p': 1, 'n_neighbors': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8073745516419146"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % KNN_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % KNN_result.best_params_)\n",
    "KNN_result.cv_results_[\"mean_test_AUC\"][KNN_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_final = KNeighborsClassifier(n_neighbors=8,p=2)\n",
    "KNN_final=KNN_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['criterion'] = [\"gini\",\"entropy\"]\n",
    "space['splitter']=[\"best\", \"random\"]\n",
    "space['min_samples_leaf']=[1,2,3,4,5,6,7,8,9,10]\n",
    "space['min_weight_fraction_leaf']=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "space['max_features']=[\"auto\",\"log2\",\"sqrt\",None]\n",
    "space['max_leaf_nodes']=[None,10,20,30,40,50,60,70,80,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(DT, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5600 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 304, in fit\n",
      "    raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "ValueError: min_weight_fraction_leaf must in [0, 0.5]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.57072515 0.57320618 0.5026908  0.51983776        nan\n",
      " 0.56548173        nan        nan 0.68856793        nan        nan\n",
      " 0.5        0.54523527        nan        nan        nan 0.5\n",
      "        nan        nan 0.62230647        nan        nan        nan\n",
      " 0.51136092 0.57354749 0.62159497        nan 0.51308491        nan\n",
      "        nan 0.54562065        nan        nan 0.57714483 0.67253173\n",
      " 0.51798511 0.51504305        nan 0.54262748 0.51246849 0.51710039\n",
      " 0.58842773 0.61182322 0.61182322        nan 0.58220626        nan\n",
      " 0.53838542        nan 0.61954046        nan 0.66747277 0.62000477\n",
      "        nan 0.51808747 0.54206306        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.1532281  0.04567211 0.         0.                nan\n",
      " 0.1368012         nan        nan 0.4704332         nan        nan\n",
      " 0.         0.                nan        nan        nan 0.\n",
      "        nan        nan 0.20487376        nan        nan        nan\n",
      " 0.         0.02370502 0.20740418        nan 0.                nan\n",
      "        nan 0.                nan        nan 0.07898319 0.46544575\n",
      " 0.         0.                nan 0.         0.         0.\n",
      " 0.         0.37405044 0.37405044        nan 0.1045724         nan\n",
      " 0.                nan 0.21757277        nan 0.44901403 0.20960718\n",
      "        nan 0.         0.00452165        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DT_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.47043320279290923\n",
      "Best Hyperparameters: {'splitter': 'best', 'min_weight_fraction_leaf': 0.1, 'min_samples_leaf': 9, 'max_leaf_nodes': None, 'max_features': 'auto', 'criterion': 'gini'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6885679302844011"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1 score: %s' % DT_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % DT_result.best_params_)\n",
    "DT_result.cv_results_[\"mean_test_AUC\"][DT_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_final = DecisionTreeClassifier(splitter=\"best\",min_weight_fraction_leaf=0.1,min_samples_leaf=9,max_leaf_nodes=None,max_features=\"auto\",criterion=\"gini\")\n",
    "DT_final=DT_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['C'] = [0.001, 0.01, 10, 100, 1000]\n",
    "space['penalty']=[\"l1\", \"l2\"]\n",
    "space['loss']=[\"hinge\", \"squared_hinge\"]\n",
    "space['class_weight']=[None,\"balanced\"]\n",
    "space[\"max_iter\"]=[2000,2500,3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = RandomizedSearchCV(SVM, space, n_iter=60,scoring=scoring, n_jobs=-1, cv=cv, random_state=1,refit=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5800 fits failed out of a total of 12000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.71902277        nan 0.71807069 0.65295353 0.68358092        nan\n",
      " 0.70926032 0.71771652        nan        nan 0.66148752 0.68192\n",
      "        nan        nan 0.69032987        nan        nan 0.64890402\n",
      " 0.71934419        nan        nan 0.66557295 0.71797745        nan\n",
      " 0.68904139        nan 0.70926026        nan 0.71738871        nan\n",
      " 0.70926027        nan        nan        nan        nan 0.68384252\n",
      "        nan        nan        nan 0.69632495 0.65545621 0.69387159\n",
      "        nan 0.6735006  0.70186624 0.71934397 0.71656317 0.71651867\n",
      "        nan 0.71807043 0.71646346        nan 0.69632498        nan\n",
      "        nan 0.6503482         nan        nan 0.66557281        nan]\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.59173238        nan 0.54808586 0.40974139 0.54487133        nan\n",
      " 0.54046697 0.54604585        nan        nan 0.39151857 0.43311931\n",
      "        nan        nan 0.50524584        nan        nan 0.39619801\n",
      " 0.59175064        nan        nan 0.55367868 0.5482316         nan\n",
      " 0.54543399        nan 0.54046697        nan 0.58768377        nan\n",
      " 0.54046697        nan        nan        nan        nan 0.54461164\n",
      "        nan        nan        nan 0.57838618 0.43102175 0.35283435\n",
      "        nan 0.4692736  0.58763941 0.59174761 0.58960378 0.58945047\n",
      "        nan 0.54808586 0.59053788        nan 0.57838618        nan\n",
      "        nan 0.412684          nan        nan 0.55369112        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SVM_result = search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5742111278286377\n",
      "Best Hyperparameters: {'penalty': 'l2', 'max_iter': 2000, 'loss': 'squared_hinge', 'class_weight': 'balanced', 'C': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7221078174042441"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best F1: %s' % SVM_result.best_score_)\n",
    "print('Best Hyperparameters: %s' % SVM_result.best_params_)\n",
    "SVM_result.cv_results_[\"mean_test_AUC\"][SVM_result.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_final = LinearSVC(penalty=\"l2\",loss='squared_hinge',class_weight='balanced',C=10,max_iter=2000)\n",
    "SVM_final=SVM_final.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = [LR_final,LDA_final,KNN_final,DT_final,SVM_final]\n",
    "model_name = ['Logisitc Regression', 'LDA', \"KNN\",'Decision Tree',\"SVM\"]\n",
    "measurement = benchmark(models,model_name,X_resampled,y_resampled,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logisitc Regression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test AUC Score</th>\n",
       "      <td>0.719959</td>\n",
       "      <td>0.712576</td>\n",
       "      <td>0.803573</td>\n",
       "      <td>0.681477</td>\n",
       "      <td>0.719362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test F-1 score</th>\n",
       "      <td>0.550787</td>\n",
       "      <td>0.544861</td>\n",
       "      <td>0.628151</td>\n",
       "      <td>0.461304</td>\n",
       "      <td>0.592504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC Score</th>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.713417</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>0.686848</td>\n",
       "      <td>0.720220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F-1 score</th>\n",
       "      <td>0.550548</td>\n",
       "      <td>0.546177</td>\n",
       "      <td>0.702950</td>\n",
       "      <td>0.460256</td>\n",
       "      <td>0.593035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Logisitc Regression       LDA       KNN  Decision Tree  \\\n",
       "Test AUC Score              0.719959  0.712576  0.803573       0.681477   \n",
       "Test F-1 score              0.550787  0.544861  0.628151       0.461304   \n",
       "Train AUC Score             0.720755  0.713417  0.881195       0.686848   \n",
       "Train F-1 score             0.550548  0.546177  0.702950       0.460256   \n",
       "\n",
       "                      SVM  \n",
       "Test AUC Score   0.719362  \n",
       "Test F-1 score   0.592504  \n",
       "Train AUC Score  0.720220  \n",
       "Train F-1 score  0.593035  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: KNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = KNN_final.predict(X_resampled)\n",
    "print(\"confusion matrix: KNN\")\n",
    "cf = confusion_matrix(y_resampled, predictions)\n",
    "sns.heatmap(cf, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How the AUC curve looks like when adding top vars\n",
    "\n",
    "AUC_b= cross_validate(KNN_final, X_resampled,y_resampled, scoring='roc_auc', cv=20,return_train_score=True)\n",
    "test_score = AUC_b[\"test_score\"].reshape(20,1)\n",
    "train_score = AUC_b[\"train_score\"].reshape(20,1)\n",
    "fold=[]\n",
    "for i in range(0,20):\n",
    "    fold = np.append(fold,i+1)\n",
    "plt.title(\"KNN Model\")\n",
    "plt.plot(fold,train_score, color='blue')\n",
    "plt.plot(fold,test_score, color='red')\n",
    "plt.xlabel('Folds')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['train = 0.88', 'test = 0.80'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81e0b57edd17c3833f38e5d4db6db81e2c0f982e51ee4890d9e870805c7d8a75"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
